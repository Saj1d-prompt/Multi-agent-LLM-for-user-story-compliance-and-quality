{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " !pip install -q google-generativeai"
      ],
      "metadata": {
        "id": "P1XM21JfZTHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THGE2veUZNxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ec3c84-553b-45a5-b3ae-e72fdf867834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q google-genai pandas faiss-cpu numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.api_core import timeout\n",
        "# Importing Libraries\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import faiss\n",
        "# from google import genai"
      ],
      "metadata": {
        "id": "A3Gm6luPZVFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Initialize the model\n",
        "model = genai.GenerativeModel('models/gemini-2.5-pro')\n",
        "\n"
      ],
      "metadata": {
        "id": "K0hSM9eUZWFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "from typing import Dict, List\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class SingleLLMBaseline:\n",
        "    \"\"\"\n",
        "    Single LLM approach - improves user story in ONE API call\n",
        "    Compatible with Gemini 2.5 Pro or other GenAI models\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, max_retries: int = 3, base_delay: float = 30.0):\n",
        "\n",
        "        self.model = model\n",
        "        self.model_name = \"gemini-2.5-pro\"\n",
        "        self.max_retries = max_retries\n",
        "        self.base_delay = base_delay\n",
        "\n",
        "        # --- SYSTEM INSTRUCTION ---\n",
        "        self.system_instruction = \"\"\"You are an expert in user story quality improvement for Adobe Experience Manager (AEM) projects.\n",
        "\n",
        "Your task: Improve the given user story to maximize INVEST quality and AEM best practices.\n",
        "\n",
        "You must consider THREE perspectives in ONE response:\n",
        "1. Product Owner: Business value, user needs, clarity\n",
        "2. Developer: Technical feasibility, AEM implementation (HTL, Dispatcher, caching)\n",
        "3. QA: Testability, clear acceptance criteria, compliance\n",
        "\n",
        "INVEST Principles:\n",
        "- Independent\n",
        "- Negotiable\n",
        "- Valuable\n",
        "- Estimable\n",
        "- Small\n",
        "- Testable\n",
        "\n",
        "AEM-Specific Requirements:\n",
        "- Use HTL (not JSP) with context-aware escaping\n",
        "- Apply Dispatcher caching strategies\n",
        "- Mention performance metrics (e.g., \"< 2s load time\")\n",
        "- Include security considerations\n",
        "- Reference AEM Core Components where applicable\n",
        "\n",
        "Output ONLY valid JSON in this exact format:\n",
        "{\n",
        "  \"story\": \"Improved story in 'As a [user], I want [goal], so that [benefit]' format\",\n",
        "  \"acceptance_criteria\": [\n",
        "    \"Specific, measurable AC\",\n",
        "    \"Include technical details and testability\"\n",
        "  ],\n",
        "  \"risks\": [\"Risk 1\", \"Risk 2\"],\n",
        "  \"open_questions\": [\"Question 1\"],\n",
        "  \"invest_assessment\": {\n",
        "    \"independent\": 4,\n",
        "    \"negotiable\": 5,\n",
        "    \"valuable\": 4,\n",
        "    \"estimable\": 3,\n",
        "    \"small\": 4,\n",
        "    \"testable\": 5\n",
        "  },\n",
        "  \"rationale\": \"Brief explanation of improvements made\"\n",
        "}\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    def process_story(self, story: Dict) -> Dict:\n",
        "        \"\"\"Process a single story with automatic retry/backoff\"\"\"\n",
        "        start_time = time.time()\n",
        "        prompt = self._build_prompt(story)\n",
        "\n",
        "        for attempt in range(1, self.max_retries + 1):\n",
        "            try:\n",
        "                response = self.model.generate_content(prompt)\n",
        "                result = self._parse_json(response.text)\n",
        "                result['processing_time'] = time.time() - start_time\n",
        "                result['model_used'] = self.model_name\n",
        "                result['iterations'] = 1\n",
        "                result['approach'] = 'single_llm'\n",
        "                result['original_story'] = story\n",
        "                return result\n",
        "\n",
        "            except Exception as e:\n",
        "                msg = str(e)\n",
        "                if \"429\" in msg or \"quota\" in msg.lower() or \"503\" in msg:\n",
        "                    wait_time = self.base_delay * attempt + random.uniform(1, 10)\n",
        "                    print(f\"‚ö†Ô∏è  Rate limit hit (attempt {attempt}/{self.max_retries}). Waiting {wait_time:.1f}s...\")\n",
        "                    time.sleep(wait_time)\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"‚ùå Error: {e}\")\n",
        "                    return {\n",
        "                        \"error\": str(e),\n",
        "                        \"original_story\": story,\n",
        "                        \"processing_time\": time.time() - start_time,\n",
        "                        \"approach\": \"single_llm\"\n",
        "                    }\n",
        "\n",
        "        # If all retries failed\n",
        "        print(f\"‚ùå All retries failed for story '{story.get('title', 'Unknown')}'\")\n",
        "        return {\n",
        "            \"error\": \"Exceeded retry limit\",\n",
        "            \"original_story\": story,\n",
        "            \"processing_time\": time.time() - start_time,\n",
        "            \"approach\": \"single_llm\"\n",
        "        }\n",
        "\n",
        "\n",
        "    def _build_prompt(self, story: Dict) -> str:\n",
        "        acs = story.get(\"acceptance_criteria\")\n",
        "        if isinstance(acs, list):\n",
        "            acs_formatted = \"\\n\".join([f\"- {a}\" for a in acs])\n",
        "        elif isinstance(acs, str):\n",
        "            acs_formatted = \"\\n\".join([f\"- {a.strip()}\" for a in acs.split(\"|\")])\n",
        "        else:\n",
        "            acs_formatted = \"None provided\"\n",
        "\n",
        "        return f\"\"\"{self.system_instruction}\n",
        "\n",
        "USER STORY TO IMPROVE:\n",
        "Title: {story.get('title', 'Untitled')}\n",
        "Description: {story.get('description', 'No description')}\n",
        "Current Acceptance Criteria:\n",
        "{acs_formatted}\n",
        "Domain/Tags: {story.get('domain', story.get('tags', 'general'))}\n",
        "\n",
        "Please improve this user story following the INVEST and AEM guidelines.\n",
        "Output ONLY the JSON (no markdown).\"\"\"\n",
        "\n",
        "\n",
        "    def _parse_json(self, text: str) -> Dict:\n",
        "        text = text.strip()\n",
        "        if text.startswith(\"```json\"):\n",
        "            text = text[7:]\n",
        "        elif text.startswith(\"```\"):\n",
        "            text = text[3:]\n",
        "        if text.endswith(\"```\"):\n",
        "            text = text[:-3]\n",
        "\n",
        "        start = text.find(\"{\")\n",
        "        end = text.rfind(\"}\") + 1\n",
        "        if start == -1 or end == 0:\n",
        "            raise ValueError(\"No JSON found in response\")\n",
        "\n",
        "        json_str = text[start:end]\n",
        "        return json.loads(json_str)\n",
        "\n",
        "    def process_multiple_stories(self, stories: List[Dict], delay: float = 35.0) -> List[Dict]:\n",
        "        results = []\n",
        "        total = len(stories)\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"üéØ SINGLE LLM BASELINE - Processing {total} stories\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        for i, story in enumerate(stories, 1):\n",
        "            print(f\"[{i}/{total}] Processing: {story.get('title', 'Untitled')}\")\n",
        "            result = self.process_story(story)\n",
        "            results.append(result)\n",
        "\n",
        "            if 'error' not in result:\n",
        "                invest = result.get(\"invest_assessment\", {})\n",
        "                if invest:\n",
        "                    avg = sum(invest.values()) / len(invest)\n",
        "                    print(f\"  ‚úì INVEST avg: {avg:.2f}/5 | Time: {result['processing_time']:.2f}s\")\n",
        "                else:\n",
        "                    print(f\"  ‚úì Processed in {result['processing_time']:.2f}s\")\n",
        "            else:\n",
        "                print(f\"  ‚úó Error: {result['error']}\")\n",
        "\n",
        "            if i < total:\n",
        "                print(f\"  ‚è≥ Waiting {delay}s for rate limit...\")\n",
        "                time.sleep(delay + random.uniform(1, 5))\n",
        "            print()\n",
        "\n",
        "        print(f\"{'='*70}\\n‚úÖ COMPLETED - Single LLM Run Finished\\n{'='*70}\")\n",
        "        return results\n",
        "\n",
        "\n",
        "    def save_results(self, results: List[Dict], filename: str = \"single_llm_results.csv\"):\n",
        "        flattened = []\n",
        "        for r in results:\n",
        "            if \"error\" in r:\n",
        "                flattened.append({\n",
        "                    \"approach\": \"single_llm\",\n",
        "                    \"original_title\": r.get(\"original_story\", {}).get(\"title\", \"Unknown\"),\n",
        "                    \"error\": r[\"error\"],\n",
        "                    \"processing_time\": r.get(\"processing_time\", 0)\n",
        "                })\n",
        "            else:\n",
        "                inv = r.get(\"invest_assessment\", {})\n",
        "                avg = sum(inv.values()) / len(inv) if inv else 0\n",
        "                flattened.append({\n",
        "                    \"approach\": \"single_llm\",\n",
        "                    \"original_title\": r[\"original_story\"][\"title\"],\n",
        "                    \"improved_story\": r[\"story\"],\n",
        "                    \"acceptance_criteria\": \" | \".join(r.get(\"acceptance_criteria\", [])),\n",
        "                    \"risks\": \" | \".join(r.get(\"risks\", [])),\n",
        "                    \"open_questions\": \" | \".join(r.get(\"open_questions\", [])),\n",
        "                    \"invest_average\": avg,\n",
        "                    \"processing_time\": r[\"processing_time\"],\n",
        "                    \"rationale\": r.get(\"rationale\", \"\")\n",
        "                })\n",
        "\n",
        "        df = pd.DataFrame(flattened)\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"\\nüíæ Results saved to: {filename}\")\n",
        "        return df\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vcBRs4plZYC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"./user_stories.csv\")\n",
        "\n",
        "print(\"Loaded stories:\", df.shape)\n",
        "df.head()\n",
        "\n",
        "stories_to_process = []\n",
        "\n",
        "for _, row in df.head(3).iterrows():\n",
        "    # acceptance criteria in your dataset use \" | \" separator\n",
        "    if isinstance(row[\"acceptance_criteria\"], str):\n",
        "        ac_list = [ac.strip() for ac in row[\"acceptance_criteria\"].split(\"|\") if ac.strip()]\n",
        "    else:\n",
        "        ac_list = []\n",
        "\n",
        "    story_dict = {\n",
        "        \"title\": row[\"title\"],\n",
        "        \"description\": row[\"description\"],\n",
        "        \"acceptance_criteria\": ac_list,\n",
        "        \"domain\": row.get(\"domain\", \"\"),\n",
        "        \"tags\": row.get(\"tags\", \"\")\n",
        "    }\n",
        "\n",
        "    stories_to_process.append(story_dict)\n",
        "\n",
        "print(\"\\nPrepared 3 stories for processing:\")\n",
        "for s in stories_to_process:\n",
        "    print(\" -\", s[\"title\"])\n",
        "\n",
        "\n",
        "baseline = SingleLLMBaseline(model)\n",
        "\n",
        "\n",
        "print(\"\\nüü¶ Running Single LLM Baseline on 3 stories...\\n\")\n",
        "\n",
        "results = baseline.process_multiple_stories(stories_to_process, delay=3.0)\n",
        "\n",
        "\n",
        "print(\"\\n====================== RESULTS ======================\\n\")\n",
        "\n",
        "for idx, r in enumerate(results, start=1):\n",
        "    print(f\"\\n---------------- Story {idx} ----------------\")\n",
        "\n",
        "    if \"error\" in r:\n",
        "        print(\"‚ùå ERROR:\", r[\"error\"])\n",
        "        continue\n",
        "\n",
        "    print(\"\\n‚ú® Improved Story:\")\n",
        "    print(r[\"story\"])\n",
        "\n",
        "    print(\"\\nüìå Acceptance Criteria:\")\n",
        "    for ac in r.get(\"acceptance_criteria\", []):\n",
        "        print(\" -\", ac)\n",
        "\n",
        "    print(\"\\n‚ö†Ô∏è Risks:\")\n",
        "    for risk in r.get(\"risks\", []):\n",
        "        print(\" -\", risk)\n",
        "\n",
        "    print(\"\\n‚ùì Open Questions:\")\n",
        "    for q in r.get(\"open_questions\", []):\n",
        "        print(\" -\", q)\n",
        "\n",
        "    print(\"\\nINVEST Assessment:\", r.get(\"invest_assessment\", {}))\n",
        "\n",
        "    print(\"\\n‚è± Processing Time:\", r.get(\"processing_time\", 0), \"sec\")\n",
        "\n",
        "print(\"\\n=====================================================\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ahiZXo1wZbL5",
        "outputId": "e47d9a34-4d68-4c17-b35a-fb651d3c04a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded stories: (90, 12)\n",
            "\n",
            "Prepared 3 stories for processing:\n",
            " - Implement GraphQL APIs to enhance performance\n",
            " - Configure Core Components to enable headless publishing\n",
            " - Configure JSON Exporter to improve author efficiency\n",
            "\n",
            "üü¶ Running Single LLM Baseline on 3 stories...\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üéØ SINGLE LLM BASELINE - Processing 3 stories\n",
            "======================================================================\n",
            "\n",
            "[1/3] Processing: Implement GraphQL APIs to enhance performance\n",
            "  ‚úì INVEST avg: 4.50/5 | Time: 30.57s\n",
            "  ‚è≥ Waiting 3.0s for rate limit...\n",
            "\n",
            "[2/3] Processing: Configure Core Components to enable headless publishing\n",
            "  ‚úì INVEST avg: 4.33/5 | Time: 25.99s\n",
            "  ‚è≥ Waiting 3.0s for rate limit...\n",
            "\n",
            "[3/3] Processing: Configure JSON Exporter to improve author efficiency\n",
            "  ‚úì INVEST avg: 4.33/5 | Time: 31.62s\n",
            "\n",
            "======================================================================\n",
            "‚úÖ COMPLETED - Single LLM Run Finished\n",
            "======================================================================\n",
            "\n",
            "====================== RESULTS ======================\n",
            "\n",
            "\n",
            "---------------- Story 1 ----------------\n",
            "\n",
            "‚ú® Improved Story:\n",
            "As a mobile app user, I want to view a list of articles with their title, summary, and author, so that I can quickly browse the latest content on the go.\n",
            "\n",
            "üìå Acceptance Criteria:\n",
            " - GIVEN the 'Article' Content Fragment Model is configured for the project's GraphQL endpoint, WHEN a client executes the `articleList` persisted query, THEN the response MUST be a JSON object containing a list of articles, each with `title` (String), `summary` (String), and `author` (String) fields.\n",
            " - The `articleList` persisted query MUST support pagination using `offset` and `limit` arguments, with a default `limit` of 10 if not specified.\n",
            " - GIVEN an article exists in both `en` and `fr` language masters, WHEN the query is made against the French-specific endpoint, THEN only the French version of the article content MUST be returned.\n",
            " - The P95 server response time for the `articleList` persisted query, measured at the AEM Publish instance before the Dispatcher, MUST be less than 200ms.\n",
            " - The GraphQL API response for GET requests using persisted queries MUST include `Cache-Control: max-age=300` and `Surrogate-Control: max-age=3600` HTTP headers to enable browser and CDN caching.\n",
            " - The AEM Dispatcher configuration MUST be updated to allow GET requests to the GraphQL endpoint for persisted queries and block arbitrary POST requests to prevent expensive or malicious queries.\n",
            " - The GraphQL endpoint MUST return the `Content-Type: application/json;charset=utf-8` header for all successful responses.\n",
            "\n",
            "‚ö†Ô∏è Risks:\n",
            " - The 'Article' Content Fragment Model may be missing required fields (e.g., author), requiring a schema change and content update effort.\n",
            " - Initial performance testing might reveal that the query is more complex than anticipated, requiring optimization of the Content Fragment Model structure.\n",
            "\n",
            "‚ùì Open Questions:\n",
            " - What are the specific filtering and sorting requirements for the article list (e.g., by date, by tag) to be addressed in a subsequent story?\n",
            "\n",
            "INVEST Assessment: {'independent': 4, 'negotiable': 5, 'valuable': 5, 'estimable': 4, 'small': 4, 'testable': 5}\n",
            "\n",
            "‚è± Processing Time: 30.57150149345398 sec\n",
            "\n",
            "---------------- Story 2 ----------------\n",
            "\n",
            "‚ú® Improved Story:\n",
            "As a Content Strategist, I want to expose website page content as structured JSON, so that our mobile app and partner single-page applications can consume it programmatically for a consistent cross-channel experience.\n",
            "\n",
            "üìå Acceptance Criteria:\n",
            " - Given a page template configured to use the project's proxy of the AEM Core Components (e.g., Title, Text, Image), when that page is requested with the `.model.json` selector, then a valid JSON representation of the page and its components must be returned.\n",
            " - The JSON response for published, publicly-accessible pages must be cached at the AEM Dispatcher. Subsequent anonymous requests for the same `.model.json` URL must be served from the cache, verifiable via a `X-Cache: HIT` or similar response header.\n",
            " - The AEM Core Components must be proxied into the project-specific path (`/apps/<project-name>/components`) and not modified directly under `/apps/core/wcm/components`.\n",
            " - The server-side response time for generating the `.model.json` for a typical content page must be under 500ms, and the end-user load time via CDN/Dispatcher must be under 2 seconds.\n",
            " - The generated JSON must not expose sensitive JCR repository paths (e.g., `/content/...`) and all string values must be correctly escaped to prevent cross-site scripting (XSS) vulnerabilities in consumer applications. This is handled by the Sling Model Exporter framework but must be verified.\n",
            " - The implementation must exclusively use HTL for the HTML rendering of the components; no JSPs are permitted.\n",
            " - Dispatcher configuration must be updated to explicitly allow and cache requests with the `.model.json` selector and `application/json` content type for anonymous users.\n",
            "\n",
            "‚ö†Ô∏è Risks:\n",
            " - The structure of the exported JSON creates a contract with consuming applications. Future changes to components could be breaking changes.\n",
            " - Large, complex pages could result in very large JSON payloads, potentially impacting consumer application performance.\n",
            "\n",
            "‚ùì Open Questions:\n",
            " - Which specific AEM Core Components are in scope for this initial implementation (e.g., Text, Title, Image, List)?\n",
            " - What is the required caching TTL (Time To Live) for the JSON content at the Dispatcher and CDN?\n",
            "\n",
            "INVEST Assessment: {'independent': 4, 'negotiable': 5, 'valuable': 5, 'estimable': 3, 'small': 4, 'testable': 5}\n",
            "\n",
            "‚è± Processing Time: 25.989850282669067 sec\n",
            "\n",
            "---------------- Story 3 ----------------\n",
            "\n",
            "‚ú® Improved Story:\n",
            "As a mobile app user, I want to view news articles in my preferred language (English or French), so that I can receive timely and relevant content on the go.\n",
            "\n",
            "üìå Acceptance Criteria:\n",
            " - A Content Fragment Model named 'Article' must be created in AEM with the following fields and data types: 'headline' (Text), 'author' (Text), 'publishDate' (Date), 'mainImage' (Content Reference to an Image Asset), and 'body' (Multi-line Text).\n",
            " - GIVEN a user creates an 'Article' Content Fragment in the '/content/dam/my-project/en' folder, WHEN they use the 'language copy' feature, THEN an equivalent fragment structure is created in '/content/dam/my-project/fr' for translation.\n",
            " - A persisted GraphQL query must be created to fetch a single Article by its content fragment path. The query must return all defined fields and the '_locale' of the content.\n",
            " - WHEN the persisted GraphQL query endpoint is called with the appropriate path and `_locale` variable set to 'fr', THEN the JSON response must contain the French content, and the `_locale` property in the response must be 'fr'.\n",
            " - The GraphQL endpoint response from AEM Publish must include HTTP caching headers: `Cache-Control: max-age=600` and `Surrogate-Control: max-age=1800` to enable browser, CDN, and Dispatcher caching.\n",
            " - The P95 server response time for the persisted GraphQL query, measured at the AEM Publish instance, must be less than 500ms under simulated load.\n",
            " - The persisted query endpoint must be configured for public, read-only access. No authentication token should be required to fetch article data.\n",
            "\n",
            "‚ö†Ô∏è Risks:\n",
            " - The initial data model for the 'Article' may not cover all future needs, requiring breaking changes to the GraphQL schema later.\n",
            " - Content translation workflow is not defined in this story and will be handled separately, potentially delaying the availability of French content for testing.\n",
            "\n",
            "‚ùì Open Questions:\n",
            " - What specific image renditions (e.g., 'mobile-hero', 'thumbnail') should the GraphQL query expose for the `mainImage` field to optimize mobile delivery?\n",
            "\n",
            "INVEST Assessment: {'independent': 4, 'negotiable': 5, 'valuable': 4, 'estimable': 4, 'small': 4, 'testable': 5}\n",
            "\n",
            "‚è± Processing Time: 31.615407943725586 sec\n",
            "\n",
            "=====================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph RAG\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "from google import genai\n",
        "\n",
        "# Configure your API key\n",
        "API_KEY = \"GEMINI_API_KEY\"\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "# Load policies\n",
        "policies_df = pd.read_csv(\"./policies.csv\")\n",
        "policy_texts = policies_df[\"clause_text\"].astype(str).tolist()\n",
        "policy_ids = policies_df[\"policy_id\"].tolist()  # ensure this column exists\n",
        "\n",
        "def embed(texts):\n",
        "    resp = client.models.embed_content(\n",
        "        model=\"gemini-embedding-001\",\n",
        "        contents=texts\n",
        "    )\n",
        "    embeddings = [np.array(embed.values, dtype=np.float32) for embed in resp.embeddings]\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "policy_embeddings = embed(policy_texts)\n",
        "policy_embeddings_norm = policy_embeddings / np.linalg.norm(policy_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "index = faiss.IndexFlatIP(policy_embeddings_norm.shape[1])\n",
        "index.add(policy_embeddings_norm)\n",
        "\n",
        "def retrieve_policies(query, k=6):\n",
        "    q = embed([query])[0]\n",
        "    q = q / np.linalg.norm(q)\n",
        "    D, I = index.search(q.reshape(1, -1), k)\n",
        "    out = []\n",
        "    for idx, score in zip(I[0], D[0]):\n",
        "        out.append({\n",
        "            \"policy_id\": policy_ids[idx],\n",
        "            \"clause_text\": policy_texts[idx],\n",
        "            \"score\": float(score)\n",
        "        })\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "dv-O6XQXERS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multi agent without Graph RAG\n",
        "\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "class MultiAgentLLM:\n",
        "    \"\"\"\n",
        "    Multi-Agent LLM pipeline (PO ‚Üí DEV ‚Üí QA)\n",
        "    No embeddings, Gemini Free Tier compatible\n",
        "    ARM A output style\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, max_retries=3, base_delay=30.0):\n",
        "        self.model = model\n",
        "        self.max_retries = max_retries\n",
        "        self.base_delay = base_delay\n",
        "        self.model_name = \"gemini-2.5-pro\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # JSON extractor\n",
        "    # -----------------------------\n",
        "    def _extract_json(self, text):\n",
        "        text = text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        start = text.find(\"{\")\n",
        "        end = text.rfind(\"}\") + 1\n",
        "        if start == -1:\n",
        "            raise ValueError(\"No JSON object found\")\n",
        "        return json.loads(text[start:end])\n",
        "\n",
        "    # -----------------------------\n",
        "    # Gemini call with timeout + retries\n",
        "    # -----------------------------\n",
        "    def _ask(self, prompt):\n",
        "        for attempt in range(1, self.max_retries + 1):\n",
        "            try:\n",
        "                resp = self.model.generate_content(\n",
        "                    prompt,\n",
        "                    request_options={\"timeout\": 60}  # timeout fix\n",
        "                )\n",
        "                return self._extract_json(resp.text)\n",
        "\n",
        "            except Exception as e:\n",
        "                msg = str(e)\n",
        "\n",
        "                if \"timed out\" in msg or \"ReadTimeout\" in msg:\n",
        "                    wait = self.base_delay * attempt + random.uniform(1, 5)\n",
        "                    print(f\"‚è≥ Timeout. Retrying in {wait:.1f}s...\")\n",
        "                    time.sleep(wait)\n",
        "                    continue\n",
        "\n",
        "                if \"429\" in msg or \"quota\" in msg.lower() or \"503\" in msg:\n",
        "                    wait = self.base_delay * attempt + random.uniform(1, 5)\n",
        "                    print(f\"‚ö†Ô∏è Rate limit. Waiting {wait:.1f}s...\")\n",
        "                    time.sleep(wait)\n",
        "                    continue\n",
        "\n",
        "                # If other error, return fallback but don't crash\n",
        "                return {\n",
        "                    \"story\": {\"title\": \"ERROR\", \"description\": \"\"},\n",
        "                    \"acceptance_criteria\": [],\n",
        "                    \"risks\": [],\n",
        "                    \"open_questions\": [],\n",
        "                    \"qa_notes\": [],\n",
        "                    \"error\": str(e)\n",
        "                }\n",
        "\n",
        "        # exceeded retries\n",
        "        return {\n",
        "            \"story\": {\"title\": \"ERROR\", \"description\": \"\"},\n",
        "            \"acceptance_criteria\": [],\n",
        "            \"risks\": [],\n",
        "            \"open_questions\": [],\n",
        "            \"qa_notes\": [],\n",
        "            \"error\": \"Exceeded retry attempts\"\n",
        "        }\n",
        "\n",
        "    # -----------------------------\n",
        "    # Product Owner Agent\n",
        "    # -----------------------------\n",
        "    def agent_po(self, story):\n",
        "        ac = story[\"acceptance_criteria\"]\n",
        "        ac_text = \"\\n\".join(f\"- {a}\" for a in ac)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a Product Owner improving a user story.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{{\n",
        "  \"story\": {{\"title\":\"...\", \"description\":\"...\"}},\n",
        "  \"acceptance_criteria\": [\"...\"],\n",
        "  \"open_questions\": [\"...\"]\n",
        "}}\n",
        "\n",
        "TITLE: {story[\"title\"]}\n",
        "DESC: {story[\"description\"]}\n",
        "AC:\n",
        "{ac_text}\n",
        "\"\"\"\n",
        "        return self._ask(prompt)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Developer Agent\n",
        "    # -----------------------------\n",
        "    def agent_dev(self, po_out):\n",
        "        ac = po_out[\"acceptance_criteria\"]\n",
        "        ac_text = \"\\n\".join(f\"- {a}\" for a in ac)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an AEM Developer. Improve technical detail and add risks.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{{\n",
        "  \"story\": {{\"title\":\"...\", \"description\":\"...\"}},\n",
        "  \"acceptance_criteria\": [\"...\"],\n",
        "  \"risks\": [\"...\"]\n",
        "}}\n",
        "\n",
        "PO STORY:\n",
        "{po_out[\"story\"]}\n",
        "\n",
        "AC:\n",
        "{ac_text}\n",
        "\"\"\"\n",
        "        return self._ask(prompt)\n",
        "\n",
        "    # -----------------------------\n",
        "    # QA Agent\n",
        "    # -----------------------------\n",
        "    def agent_qa(self, dev_out):\n",
        "        ac = dev_out[\"acceptance_criteria\"]\n",
        "        ac_text = \"\\n\".join(f\"- {a}\" for a in ac)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are QA. Ensure clarity and testability.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{{\n",
        "  \"story\": {{\"title\":\"...\", \"description\":\"...\"}},\n",
        "  \"acceptance_criteria\": [\"...\"],\n",
        "  \"qa_notes\": [\"...\"]\n",
        "}}\n",
        "\n",
        "DEV STORY:\n",
        "{dev_out[\"story\"]}\n",
        "\n",
        "AC:\n",
        "{ac_text}\n",
        "\"\"\"\n",
        "        return self._ask(prompt)\n",
        "\n",
        "    # -----------------------------\n",
        "    # MAIN PROCESSOR\n",
        "    # -----------------------------\n",
        "    def process_story(self, story):\n",
        "        start = time.time()\n",
        "\n",
        "        po = self.agent_po(story)\n",
        "        dev = self.agent_dev(po)\n",
        "        qa = self.agent_qa(dev)\n",
        "\n",
        "        return {\n",
        "            \"approach\": \"multi_llm\",\n",
        "            \"original_title\": story[\"title\"],\n",
        "            \"story\": qa[\"story\"],\n",
        "            \"acceptance_criteria\": qa[\"acceptance_criteria\"],\n",
        "            \"risks\": dev.get(\"risks\", []),\n",
        "            \"open_questions\": po.get(\"open_questions\", []),\n",
        "            \"qa_notes\": qa.get(\"qa_notes\", []),\n",
        "            \"processing_time\": time.time() - start,\n",
        "            \"model_used\": self.model_name,\n",
        "            \"original_story\": story\n",
        "        }\n",
        "\n",
        "    # -----------------------------\n",
        "    # BATCH PROCESSOR (matching ARM A)\n",
        "    # -----------------------------\n",
        "    def process_multiple_stories(self, stories, delay=0):\n",
        "        results = []\n",
        "        for s in stories:\n",
        "            results.append(self.process_story(s))\n",
        "            if delay > 0:\n",
        "                time.sleep(delay)\n",
        "        return results\n",
        "\n",
        "    # -----------------------------\n",
        "    # SAVE RESULTS LIKE ARM A\n",
        "    # -----------------------------\n",
        "    def save_results(self, results, filename=\"arm_b_results.csv\"):\n",
        "        rows = []\n",
        "        for r in results:\n",
        "            rows.append({\n",
        "                \"approach\": r[\"approach\"],\n",
        "                \"original_title\": r[\"original_title\"],\n",
        "                \"improved_story\": r[\"story\"],\n",
        "                \"acceptance_criteria\": \" | \".join(r[\"acceptance_criteria\"]),\n",
        "                \"risks\": \" | \".join(r[\"risks\"]),\n",
        "                \"open_questions\": \" | \".join(r[\"open_questions\"]),\n",
        "                \"qa_notes\": \" | \".join(r[\"qa_notes\"]),\n",
        "                \"processing_time\": r[\"processing_time\"],\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(\"üíæ Saved:\", filename)\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "4Njvgq-1ZeND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stories_df = pd.read_csv(\"./user_stories.csv\")\n",
        "\n",
        "stories = []\n",
        "for _, r in stories_df.head(3).iterrows():\n",
        "    ac_list = [ac.strip() for ac in r[\"acceptance_criteria\"].split(\"|\")]\n",
        "\n",
        "    stories.append({\n",
        "        \"title\": r[\"title\"],\n",
        "        \"description\": r[\"description\"],\n",
        "        \"acceptance_criteria\": ac_list,\n",
        "        \"domain\": r.get(\"domain\", \"\")\n",
        "    })\n"
      ],
      "metadata": {
        "id": "6ayzXgb3ZfXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi = MultiAgentLLM(model)\n",
        "results_b = multi.process_multiple_stories(stories, delay=3)\n"
      ],
      "metadata": {
        "id": "gVRL1Mt5a7x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "print(json.dumps(results_b, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWihfbyQcGUs",
        "outputId": "77c98833-8ff2-4565-8eba-7a13064158c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"approach\": \"multi_llm\",\n",
            "    \"original_title\": \"Implement GraphQL APIs to enhance performance\",\n",
            "    \"story\": {\n",
            "      \"title\": \"Enable GraphQL Persisted Query for the 'Article' Content Fragment Model\",\n",
            "      \"description\": \"As a front-end developer, I need a secure and performant AEM GraphQL persisted query to retrieve specific fields from an 'Article' Content Fragment, so that I can efficiently populate an article details page by fetching only the necessary data and leveraging CDN/Dispatcher caching.\"\n",
            "    },\n",
            "    \"acceptance_criteria\": [\n",
            "      \"Given the AEM GraphQL endpoint is configured for the project, when the configuration is checked, then the 'Article' Content Fragment Model must be enabled.\",\n",
            "      \"A persisted GraphQL query (e.g., `my-project/article-by-path`) must be created that fetches a single Article Content Fragment.\",\n",
            "      \"The persisted query must accept two variables: `articlePath` (String, e.g., '/content/dam/my-project/articles/my-first-article') and `locale` (String, e.g., 'en-us').\",\n",
            "      \"When the query is executed, the response must successfully return data for the following fields when they are requested: `title`, `author`, `publishDate`, `heroImage`, and `mainContent`.\",\n",
            "      \"When querying the `heroImage` field, it must be possible to retrieve the nested properties: `_path`, `width`, `height`, and `format`.\",\n",
            "      \"The `mainContent` field must support format arguments, allowing the content to be retrieved as both `html` and `markdown` in separate queries.\",\n",
            "      \"When the persisted query is executed requesting *only* the `title` field, the JSON response payload must not contain any data for `heroImage` or `mainContent`.\",\n",
            "      \"When a GET request is made to the persisted query URL for the first time, the response from the Dispatcher includes a cache 'MISS' header (e.g., `x-cache: MISS`).\",\n",
            "      \"When an identical GET request is made subsequently, the response from the Dispatcher includes a cache 'HIT' header (e.g., `x-cache: HIT`).\",\n",
            "      \"After an existing Article Content Fragment is modified and republished, the next GET request for that article's data must result in a cache 'MISS' and return the updated content.\",\n",
            "      \"A Confluence page must be created or updated with the final persisted query URL, the GraphQL query definition, and a clear example of its usage with variables.\"\n",
            "    ],\n",
            "    \"risks\": [\n",
            "      {\n",
            "        \"risk\": \"Performance Degradation with Complex Fragments\",\n",
            "        \"mitigation\": \"The `mainContent` field, if modeled as a Rich Text Editor, can contain references to other Content Fragments or Assets. Deeply nested queries can negatively impact AEM Publisher response times. The query design must be analyzed for complexity, and consideration should be given to limiting the depth of fragment references resolved in a single call.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Schema Breaking Changes\",\n",
            "        \"mitigation\": \"Any modification to the 'Article' Content Fragment Model (e.g., renaming or deleting a field) is a breaking change for the GraphQL schema and will fail client applications. A versioning strategy for the API or a strict governance process for model changes must be established.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Incorrect Cache Invalidation\",\n",
            "        \"mitigation\": \"If Dispatcher cache invalidation rules are not configured correctly for Content Fragments, clients may receive stale content. The replication agent and dispatcher configuration must be thoroughly tested to ensure publishing an Article CF or a referenced `heroImage` correctly invalidates the corresponding persisted query JSON response.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Content Governance for Localization\",\n",
            "        \"mitigation\": \"The `_locale` filtering depends entirely on authors creating and maintaining language variations within each Content Fragment. If this workflow is not followed, queries for specific locales will return null or fallback content, leading to an inconsistent user experience. Author training and clear content guidelines are required.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Unauthorized Content Exposure\",\n",
            "        \"mitigation\": \"By default, the AEM GraphQL endpoint exposes all published content based on the configured models. If certain articles are intended for restricted audiences, this API could expose them publicly. This implementation assumes all articles are public; if not, Closed User Group (CUG) policies or custom authentication logic at the Dispatcher/CDN level must be investigated.\"\n",
            "      }\n",
            "    ],\n",
            "    \"open_questions\": [\n",
            "      \"Which specific fields from the Article Content Fragment Model are mandatory for the V1 launch of the article page?\",\n",
            "      \"What are the requirements for filtering or querying a list of articles (e.g., by tag, by author)? Should this be in a separate story?\",\n",
            "      \"How will authentication and authorization be handled? Is this a public or private API?\",\n",
            "      \"What are the specific performance targets (e.g., p95 latency under X ms at Y requests/sec)?\",\n",
            "      \"How should errors, such as querying for a non-existent article, be handled in the response?\"\n",
            "    ],\n",
            "    \"qa_notes\": [\n",
            "      \"Test Data Prerequisite: At least two 'Article' Content Fragments should be created. One with all fields populated, including a hero image. Another with optional fields (like hero image) left empty. Create at least one language copy (e.g., 'fr-fr') of an article to test the `_locale` variable.\",\n",
            "      \"Testing Tools: Use AEM's GraphiQL interface for initial query validation. Use a REST client (e.g., Postman, curl) to test the final persisted query GET endpoint and inspect HTTP response headers.\",\n",
            "      \"Dispatcher Cache Testing: This requires an AEM environment with a configured Dispatcher. Check response headers (`x-cache`, `age`, `cache-control`) to validate caching behavior. The exact header names may vary based on configuration.\",\n",
            "      \"Negative Test Case: Test by providing an invalid `_path` to an article. The query should gracefully handle this, likely by returning null or empty data.\",\n",
            "      \"Negative Test Case: Test by providing a `_locale` that does not exist for a given article. The query should return data for the default language or handle it as defined by the business logic.\",\n",
            "      \"Field Validation: Verify that the `publishDate` is returned in a valid ISO 8601 format. Verify that `mainContent` as HTML contains valid HTML tags.\",\n",
            "      \"Security Check: Confirm that only GET requests are allowed for this persisted query at the Dispatcher level. POST requests with arbitrary query bodies should be blocked.\"\n",
            "    ],\n",
            "    \"processing_time\": 73.47251510620117,\n",
            "    \"model_used\": \"gemini-2.5-pro\",\n",
            "    \"original_story\": {\n",
            "      \"title\": \"Implement GraphQL APIs to enhance performance\",\n",
            "      \"description\": \"As an AEM headless developer, I want to implement GraphQL APIs to enhance performance, so that the solution aligns with AEM Cloud Service best practices.\",\n",
            "      \"acceptance_criteria\": [\n",
            "        \"GraphQL schema changes must be versioned and documented.\",\n",
            "        \"APIs must support localized content variants.\",\n",
            "        \"Content Fragment Models must define explicit data types for all fields.\"\n",
            "      ],\n",
            "      \"domain\": \"headless\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"approach\": \"multi_llm\",\n",
            "    \"original_title\": \"Configure Core Components to enable headless publishing\",\n",
            "    \"story\": {\n",
            "      \"title\": \"Expose AEM Page Content as a Structured JSON API\",\n",
            "      \"description\": \"As a content consumer (e.g., a Single Page Application, mobile app), I need to retrieve the complete content structure of an AEM page, including its metadata and all its components' data, through a single, well-defined JSON API endpoint. This enables decoupled frontend applications to render pages dynamically using content managed within AEM.\"\n",
            "    },\n",
            "    \"acceptance_criteria\": [\n",
            "      \"Given a valid, published AEM page, when a GET request is made to its URL with the `.model.json` selector, the server responds with a `200 OK` status and a `Content-Type` header of `application/json`.\",\n",
            "      \"Given a non-existent AEM page path, when a GET request is made with the `.model.json` selector, the server responds with a `404 Not Found` status code.\",\n",
            "      \"The root of the returned JSON object must contain page-level properties, including `jcr:title`, `cq:lastModified`, and the page template path.\",\n",
            "      \"The JSON response must include a `:children` object representing the page's main content container, where each key is a component's node name and its value is the JSON model for that component.\",\n",
            "      \"The exported JSON for an Image component must include a `src` attribute containing a web-optimized URL processed by the AEM Core Image Servlet (e.g., containing `.coreimg.`), not a direct `/content/dam` path.\",\n",
            "      \"The exported JSON for a Text component authored with rich text must contain a property with the corresponding HTML markup, with special characters properly escaped (e.g., `<` becomes `&lt;`).\",\n",
            "      \"A GET request for a `.model.json` URL made through the dispatcher must be allowed and return the JSON payload successfully.\",\n",
            "      \"When a page is activated (published), the dispatcher cache for its corresponding `.model.json` URL must be invalidated, ensuring subsequent requests retrieve fresh content.\",\n",
            "      \"A JavaScript `fetch` request to a `.model.json` URL from an explicitly allowed frontend domain must succeed without a browser CORS (Cross-Origin Resource Sharing) policy error.\"\n",
            "    ],\n",
            "    \"risks\": [\n",
            "      {\n",
            "        \"risk\": \"Performance Degradation and Large Payloads\",\n",
            "        \"detail\": \"Pages with a deep component hierarchy or numerous components can result in slow JSON serialization on the AEM Publish instance and large, slow-to-download JSON payloads. This can negatively impact Time to First Byte (TTFB) and client-side rendering performance.\",\n",
            "        \"mitigation\": \"Establish content architecture guidelines to limit page depth. Implement pagination for list components. Ensure Dispatcher and CDN caching are correctly configured and verified. For complex scenarios, consider GraphQL endpoints for more selective data fetching.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Brittle Frontend-Backend Contract\",\n",
            "        \"detail\": \"Any unannounced change in the Sling Model's exported JSON structure (e.g., renaming a field, changing a data type) will be a breaking change for the consuming frontend application, potentially causing rendering errors or a blank page.\",\n",
            "        \"mitigation\": \"Establish a versioning strategy for the API (e.g., using a custom selector like `.v1.model.json`). Maintain a clear API contract or schema (e.g., using OpenAPI) and communicate any changes to the frontend team well in advance. Implement contract testing.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Sensitive Information Disclosure\",\n",
            "        \"detail\": \"Sling Models, if not carefully crafted, could inadvertently export internal JCR properties, system paths, or other sensitive data not intended for public consumption, creating a potential information leakage vulnerability.\",\n",
            "        \"mitigation\": \"Models should follow a 'deny-by-default' principle, only exposing fields explicitly annotated with `@JsonProperty`. Use `@JsonIgnore` to exclude unwanted fields inherited from parent models. Conduct regular security reviews of the JSON output for any exposed endpoints.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Incorrect Cache Invalidation\",\n",
            "        \"detail\": \"If Dispatcher cache invalidation rules are not configured correctly, anonymous users may be served stale JSON content after an author publishes an update. This is especially risky for referenced content (e.g., an image is updated but the page using it is not republished).\",\n",
            "        \"mitigation\": \"Thoroughly test the dispatcher flush rules, including `/statfileslevel` and invalidation rules. Ensure the replication agent on Author is correctly configured to trigger the flush. For referenced content, implement custom replication listeners or rely on TTL-based caching at the CDN as a secondary strategy.\"\n",
            "      }\n",
            "    ],\n",
            "    \"open_questions\": [\n",
            "      \"What is the full list of Core Components that must support JSON export for this story, beyond Title, Text, and Image?\",\n",
            "      \"What is the required JSON structure for page-level properties (e.g., page title, metadata, tags)?\",\n",
            "      \"How should links to other internal AEM pages be represented in the JSON (e.g., full path, relative path, externalized URL)?\",\n",
            "      \"What are the specific cache TTL (Time-To-Live) requirements for the JSON content at the Dispatcher/CDN?\",\n",
            "      \"Are there any specific component properties that should be explicitly excluded from the JSON output for security or privacy reasons?\"\n",
            "    ],\n",
            "    \"qa_notes\": [\n",
            "      \"Test Scenarios: Verify API behavior for pages that are published, unpublished, non-existent, and pages with restricted access (anonymous vs. authenticated).\",\n",
            "      \"Test Data Setup: Create a test page containing at least one of each proxy component: Title, Text (one with plain text, one with rich text including links and bolding), and Image. This page must be published.\",\n",
            "      \"Environment Checklist: Testing must be performed on AEM Author, AEM Publish, and through the Dispatcher to validate all caching and security rules.\",\n",
            "      \"CORS Testing: To validate the CORS configuration, create a simple HTML file with a JavaScript fetch call to a `.model.json` URL. Serve this file from a different domain/port (e.g., using a simple Python server or VS Code Live Server) than the AEM instance.\",\n",
            "      \"Tools: Use API testing tools like Postman or Insomnia to inspect response headers, status codes, and JSON structure. Use browser developer tools to verify CORS behavior.\",\n",
            "      \"Cache Validation: Check for `X-Cache` or similar headers returned by the dispatcher/CDN to confirm if a response is a cache hit or miss. Validate cache invalidation by updating a component on the test page, publishing it, and re-requesting the `.model.json` URL to see the updated content.\",\n",
            "      \"Security: Confirm that no sensitive repository information (e.g., user data, system paths) is exposed in the JSON output. Verify the HTML escaping in the Text component's output prevents potential XSS vectors.\",\n",
            "      \"Out of Scope: This story only covers the page model and the proxied Title, Text, and Image components. Exporting models for other components is not included.\"\n",
            "    ],\n",
            "    \"processing_time\": 85.78923797607422,\n",
            "    \"model_used\": \"gemini-2.5-pro\",\n",
            "    \"original_story\": {\n",
            "      \"title\": \"Configure Core Components to enable headless publishing\",\n",
            "      \"description\": \"As an AEM websites developer, I want to configure Core Components to enable headless publishing, so that the solution aligns with AEM Cloud Service best practices.\",\n",
            "      \"acceptance_criteria\": [\n",
            "        \"No JSP scripts or direct /apps modifications are allowed.\",\n",
            "        \"Dispatcher must cache all public content pages for anonymous users.\",\n",
            "        \"All rendered HTML must use HTL context-aware escaping to prevent XSS.\"\n",
            "      ],\n",
            "      \"domain\": \"websites\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"approach\": \"multi_llm\",\n",
            "    \"original_title\": \"Configure JSON Exporter to improve author efficiency\",\n",
            "    \"story\": {\n",
            "      \"title\": \"Establish a Production-Ready Headless GraphQL API\",\n",
            "      \"description\": \"As a headless client application (e.g., a mobile app or SPA), I need to consume content from AEM via a secure, stable, versioned, localized, and performant GraphQL API, so that I can provide a reliable and fast user experience.\"\n",
            "    },\n",
            "    \"acceptance_criteria\": [\n",
            "      \"The GraphQL schema is strongly typed, accurately reflecting data types (e.g., Number, Boolean, Date) defined in the corresponding Content Fragment Models.\",\n",
            "      \"Direct POST requests to the `/graphql/execute.json` endpoint are blocked at the Dispatcher, returning a `403 Forbidden` or `405 Method Not Allowed` status.\",\n",
            "      \"A GET request to a public-facing versioned URL (e.g., `/api/graphql/v1/my-site/my-query`) successfully resolves and returns the expected JSON payload from the corresponding AEM persisted query.\",\n",
            "      \"Querying a persisted query with a language-specific path variable (e.g., `_path='/content/dam/my-site/fr'`) returns only the content fragments from that specific language tree.\",\n",
            "      \"Successful GET responses for persisted queries include the `Cache-Control`, `Surrogate-Control`, and `ETag` HTTP headers, with TTL values matching the current OSGi configuration.\",\n",
            "      \"An OPTIONS preflight request from a whitelisted origin to the GraphQL endpoint returns a `200 OK` status with the appropriate `Access-Control-Allow-Origin` header, while requests from non-whitelisted origins are blocked.\",\n",
            "      \"A single GraphQL query can retrieve a parent Content Fragment and its referenced (nested) Content Fragments, including specific fields from the nested fragments.\",\n",
            "      \"The `ui.config` module contains a `CHANGELOG.md` file that documents all structural changes to persisted queries using 'Added', 'Changed', 'Deprecated', or 'Removed' categories.\"\n",
            "    ],\n",
            "    \"risks\": [\n",
            "      {\n",
            "        \"risk\": \"Schema Evolution and Breaking Changes\",\n",
            "        \"detail\": \"Content authors modifying Content Fragment Models (e.g., changing a field's data type or making a required field optional) can inadvertently introduce breaking changes to the GraphQL schema, impacting live frontend applications.\",\n",
            "        \"mitigation\": \"Establish a strict governance process for CFM changes. Implement a CI/CD pipeline step that introspects the GraphQL schema and fails the build if a breaking change is detected without a corresponding major version bump. Use the `@deprecated` directive on fields before scheduling them for removal.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Query Performance Degradation\",\n",
            "        \"detail\": \"Deeply nested fragment references or queries requesting large datasets can cause high CPU and memory usage on AEM Publish instances, leading to slow response times or service instability.\",\n",
            "        \"mitigation\": \"Enforce pagination in all list-based queries using `first` and `after` arguments. Proactively monitor slow queries in AEM logs. Collaborate with the frontend team to optimize and limit query depth. Use Persisted Queries exclusively to prevent malicious or inefficient ad-hoc queries.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Complex Cache Invalidation\",\n",
            "        \"detail\": \"An aggressive caching strategy at the Dispatcher/CDN can lead to stale content being served. Correctly invalidating GraphQL query responses when underlying Content Fragments are updated is non-trivial, as one fragment can affect many API responses.\",\n",
            "        \"mitigation\": \"Implement a targeted cache invalidation strategy using Dispatcher's cache flushing rules that trigger on content activation. For highly dynamic content, use shorter TTLs. Ensure any custom caching layers correctly interpret `Surrogate-Key` or similar headers if available.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Inconsistent Localization Handling\",\n",
            "        \"detail\": \"If the frontend application builds its own logic for determining the language path (e.g., `/content/dam/my-site/en-us` vs `/content/dam/my-site/en_us`), it can lead to inconsistencies and failed queries. AEM's OOTB GraphQL API does not automatically infer locale from a browser header.\",\n",
            "        \"mitigation\": \"Clearly document the expected language-root path format for the frontend team. The responsibility for constructing the correct path within the GraphQL query (`_path` filter) must reside with the client. Avoid building custom language resolution logic in AEM.\"\n",
            "      },\n",
            "      {\n",
            "        \"risk\": \"Security Vulnerabilities\",\n",
            "        \"detail\": \"An improperly secured GraphQL endpoint can expose excessive data or be vulnerable to Denial of Service (DoS) attacks through overly complex queries. Leaving ad-hoc queries enabled in production is a significant security risk.\",\n",
            "        \"mitigation\": \"Strictly use Persisted Queries and disable ad-hoc queries via Dispatcher filters. Ensure CORS policies are narrowly configured to only allow trusted domains. Regularly audit permissions on the underlying content fragments to prevent unauthorized data exposure.\"\n",
            "      }\n",
            "    ],\n",
            "    \"open_questions\": [\n",
            "      \"What is the initial list of languages/locales to be supported at launch?\",\n",
            "      \"What is the agreed-upon naming convention for Content Fragment Models and their fields to ensure a clean and consistent GraphQL schema?\",\n",
            "      \"Should the API support filtering or pagination for multi-valued fields (e.g., Fragment References)? If so, what are the requirements?\",\n",
            "      \"What are the specific TTL (Time To Live) values required for the cache headers?\",\n",
            "      \"How should nested Content Fragments be handled in the JSON: inlined content or references (links)?\"\n",
            "    ],\n",
            "    \"qa_notes\": [\n",
            "      {\n",
            "        \"area\": \"Test Data Strategy\",\n",
            "        \"notes\": [\n",
            "          \"Requires Content Fragment Models utilizing a variety of data types: Number, Boolean, Date & Time, Enum, Tags, and especially Fragment Reference.\",\n",
            "          \"Requires a multi-lingual content structure in the DAM (e.g., `/content/dam/my-site/en`, `/content/dam/my-site/fr`, `/content/dam/my-site/es`) with sample content in each language.\",\n",
            "          \"Requires at least one pair of Content Fragments demonstrating a parent-child relationship via Fragment Reference (e.g., an 'Article' referencing an 'Author').\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"area\": \"Environment & Tooling\",\n",
            "        \"notes\": [\n",
            "          \"Dispatcher-level tests (URL rewrites, POST request blocking) must be performed on an environment with a configured Dispatcher.\",\n",
            "          \"Use Postman or cURL to inspect HTTP headers (`Cache-Control`, `ETag`, CORS headers) and status codes.\",\n",
            "          \"Use browser developer tools to validate CORS policy by making requests from both allowed and disallowed domains/origins.\",\n",
            "          \"AEM's GraphiQL interface can be used to validate the schema and test persisted queries directly against Publish instances.\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"area\": \"Testing Scenarios\",\n",
            "        \"notes\": [\n",
            "          \"**Versioning:** Verify that the URL rewrite rule `api/graphql/v1/...` works. Discuss how a future `v2` would be implemented without affecting `v1`.\",\n",
            "          \"**Caching:** After verifying initial caching headers, update the TTLs in the OSGi config, deploy the change, and re-test to ensure the new values are reflected in the response headers.\",\n",
            "          \"**Security (CORS):** Test preflight (OPTIONS) and actual (GET) requests from: 1) a whitelisted domain, 2) a non-whitelisted domain, and 3) localhost.\",\n",
            "          \"**Security (POST block):** Attempt to send a valid GraphQL query via a POST request directly to `/graphql/execute.json` through the dispatcher; it must be rejected.\",\n",
            "          \"**Error Handling:** Test persisted queries with invalid parameters (e.g., a non-existent `_path`) to ensure a graceful error response is returned.\",\n",
            "          \"**Changelog:** This is a process validation. During code review, verify that any PR modifying a persisted query also includes a corresponding update to `CHANGELOG.md`.\"\n",
            "        ]\n",
            "      }\n",
            "    ],\n",
            "    \"processing_time\": 85.38955521583557,\n",
            "    \"model_used\": \"gemini-2.5-pro\",\n",
            "    \"original_story\": {\n",
            "      \"title\": \"Configure JSON Exporter to improve author efficiency\",\n",
            "      \"description\": \"As an AEM headless developer, I want to configure JSON Exporter to improve author efficiency, so that the solution aligns with AEM Cloud Service best practices.\",\n",
            "      \"acceptance_criteria\": [\n",
            "        \"Content Fragment Models must define explicit data types for all fields.\",\n",
            "        \"APIs must support localized content variants.\",\n",
            "        \"GraphQL schema changes must be versioned and documented.\"\n",
            "      ],\n",
            "      \"domain\": \"headless\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# import time\n",
        "# import random\n",
        "# import pandas as pd\n",
        "\n",
        "# class MultiAgentLLM_RAG:\n",
        "#     \"\"\"\n",
        "#     Multi-Agent LLM pipeline with RAG (PO ‚Üí DEV ‚Üí QA)\n",
        "#     Uses FAISS/embedding retrieval to provide context\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, model, retrieve_fn, top_k=3, max_retries=3, base_delay=30.0):\n",
        "#         self.model = model\n",
        "#         self.retrieve_fn = retrieve_fn\n",
        "#         self.top_k = top_k\n",
        "#         self.max_retries = max_retries\n",
        "#         self.base_delay = base_delay\n",
        "#         self.model_name = \"gemini-2.5-pro\"\n",
        "\n",
        "#     def _extract_json(self, text):\n",
        "#         text = text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "#         start = text.find(\"{\")\n",
        "#         end = text.rfind(\"}\") + 1\n",
        "#         if start == -1:\n",
        "#             raise ValueError(\"No JSON object found\")\n",
        "#         return json.loads(text[start:end])\n",
        "\n",
        "#     def _ask(self, prompt):\n",
        "#         for attempt in range(1, self.max_retries + 1):\n",
        "#             try:\n",
        "#                 resp = self.model.generate_content(prompt, request_options={\"timeout\": 60})\n",
        "#                 return self._extract_json(resp.text)\n",
        "#             except Exception as e:\n",
        "#                 msg = str(e)\n",
        "#                 if \"timed out\" in msg or \"ReadTimeout\" in msg:\n",
        "#                     wait = self.base_delay * attempt + random.uniform(1,5)\n",
        "#                     time.sleep(wait)\n",
        "#                     continue\n",
        "#                 if \"429\" in msg or \"quota\" in msg.lower() or \"503\" in msg:\n",
        "#                     wait = self.base_delay * attempt + random.uniform(1,5)\n",
        "#                     time.sleep(wait)\n",
        "#                     continue\n",
        "#                 return {\n",
        "#                     \"story\": {\"title\":\"ERROR\",\"description\":\"\"},\n",
        "#                     \"acceptance_criteria\": [],\n",
        "#                     \"risks\": [],\n",
        "#                     \"open_questions\": [],\n",
        "#                     \"qa_notes\": [],\n",
        "#                     \"error\": str(e)\n",
        "#                 }\n",
        "#         return {\n",
        "#             \"story\": {\"title\":\"ERROR\",\"description\":\"\"},\n",
        "#             \"acceptance_criteria\": [],\n",
        "#             \"risks\": [],\n",
        "#             \"open_questions\": [],\n",
        "#             \"qa_notes\": [],\n",
        "#             \"error\": \"Exceeded retry attempts\"\n",
        "#         }\n",
        "\n",
        "#     def _get_context_text(self, story):\n",
        "#       description = story.get(\"description\", \"\")\n",
        "#       if not description.strip():\n",
        "#           description = \"No story description provided.\"\n",
        "#       retrieved = self.retrieve_fn(description, self.top_k)\n",
        "#       if not retrieved or all(not r.get(\"clause_text\",\"\").strip() for r in retrieved):\n",
        "#           return \"No relevant policy context available.\"\n",
        "#       return \"\\n\".join([r[\"clause_text\"] for r in retrieved])\n",
        "\n",
        "\n",
        "#     def agent_po(self, story):\n",
        "#       query = story[\"description\"]\n",
        "#       retrieved = retrieve_policies(query, k=3)  # returns list of dicts\n",
        "\n",
        "#       if not retrieved:\n",
        "#           retrieved_text = \"No relevant policies found.\"\n",
        "#       else:\n",
        "#           retrieved_text = \"\\n\".join([r[\"clause_text\"] for r in retrieved])\n",
        "\n",
        "#       ac_text = \"\\n\".join(f\"- {a}\" for a in story[\"acceptance_criteria\"])\n",
        "\n",
        "#       prompt = f\"\"\"\n",
        "#   You are a Product Owner improving a user story. Use the retrieved policies to enhance it.\n",
        "\n",
        "#   Retrieved Policies:\n",
        "#   {retrieved_text}\n",
        "\n",
        "#   Return ONLY JSON:\n",
        "#   {{\n",
        "#     \"story\": {{\"title\":\"...\", \"description\":\"...\"}},\n",
        "#     \"acceptance_criteria\": [\"...\"],\n",
        "#     \"open_questions\": [\"...\"]\n",
        "#   }}\n",
        "\n",
        "#   TITLE: {story[\"title\"]}\n",
        "#   DESC: {story[\"description\"]}\n",
        "#   AC:\n",
        "#   {ac_text}\n",
        "#   \"\"\"\n",
        "#       return self._ask(prompt)\n",
        "\n",
        "\n",
        "#     def agent_dev(self, po_out):\n",
        "#         ac_text = \"\\n\".join(f\"- {a}\" for a in po_out[\"acceptance_criteria\"])\n",
        "#         retrieved_text = self._get_context_text(po_out[\"story\"])\n",
        "\n",
        "#         prompt = f\"\"\"\n",
        "# You are an AEM Developer. Improve technical detail and add risks.\n",
        "\n",
        "# Context policies:\n",
        "# {retrieved_text}\n",
        "\n",
        "# Return ONLY JSON:\n",
        "# {{\n",
        "#   \"story\": {{\"title\":\"...\", \"description\":\"...\"}},\n",
        "#   \"acceptance_criteria\": [\"...\"],\n",
        "#   \"risks\": [\"...\"]\n",
        "# }}\n",
        "\n",
        "# PO STORY:\n",
        "# {po_out[\"story\"]}\n",
        "\n",
        "# AC:\n",
        "# {ac_text}\n",
        "# \"\"\"\n",
        "#         return self._ask(prompt)\n",
        "\n",
        "#     def agent_qa(self, dev_out):\n",
        "#         ac_text = \"\\n\".join(f\"- {a}\" for a in dev_out[\"acceptance_criteria\"])\n",
        "#         retrieved_text = self._get_context_text(dev_out[\"story\"])\n",
        "\n",
        "#         prompt = f\"\"\"\n",
        "# You are QA. Ensure clarity and testability.\n",
        "\n",
        "# Context policies:\n",
        "# {retrieved_text}\n",
        "\n",
        "# Return ONLY JSON:\n",
        "# {{\n",
        "#   \"story\": {{\"title\":\"...\", \"description\":\"...\"}},\n",
        "#   \"acceptance_criteria\": [\"...\"],\n",
        "#   \"qa_notes\": [\"...\"]\n",
        "# }}\n",
        "\n",
        "# DEV STORY:\n",
        "# {dev_out[\"story\"]}\n",
        "\n",
        "# AC:\n",
        "# {ac_text}\n",
        "# \"\"\"\n",
        "#         return self._ask(prompt)\n",
        "\n",
        "#     def process_story(self, story):\n",
        "#         start = time.time()\n",
        "#         po = self.agent_po(story)\n",
        "#         dev = self.agent_dev(po)\n",
        "#         qa = self.agent_qa(dev)\n",
        "\n",
        "#         return {\n",
        "#             \"approach\": \"multi_llm_rag\",\n",
        "#             \"original_title\": story[\"title\"],\n",
        "#             \"story\": qa[\"story\"],\n",
        "#             \"acceptance_criteria\": qa[\"acceptance_criteria\"],\n",
        "#             \"risks\": dev.get(\"risks\", []),\n",
        "#             \"open_questions\": po.get(\"open_questions\", []),\n",
        "#             \"qa_notes\": qa.get(\"qa_notes\", []),\n",
        "#             \"processing_time\": time.time() - start,\n",
        "#             \"model_used\": self.model_name,\n",
        "#             \"original_story\": story\n",
        "#         }\n",
        "\n",
        "#     def process_multiple_stories(self, stories, delay=0):\n",
        "#         results = []\n",
        "#         for s in stories:\n",
        "#             results.append(self.process_story(s))\n",
        "#             if delay > 0:\n",
        "#                 time.sleep(delay)\n",
        "#         return results\n",
        "\n",
        "#     def save_results(self, results, filename=\"multi_agent_rag_results.csv\"):\n",
        "#         rows = []\n",
        "#         for r in results:\n",
        "#             rows.append({\n",
        "#                 \"approach\": r[\"approach\"],\n",
        "#                 \"original_title\": r[\"original_title\"],\n",
        "#                 \"improved_story\": r[\"story\"],\n",
        "#                 \"acceptance_criteria\": \" | \".join(r[\"acceptance_criteria\"]),\n",
        "#                 \"risks\": \" | \".join(r[\"risks\"]),\n",
        "#                 \"open_questions\": \" | \".join(r[\"open_questions\"]),\n",
        "#                 \"qa_notes\": \" | \".join(r[\"qa_notes\"]),\n",
        "#                 \"processing_time\": r[\"processing_time\"],\n",
        "#             })\n",
        "#         df = pd.DataFrame(rows)\n",
        "#         df.to_csv(filename, index=False)\n",
        "#         print(\"üíæ Saved:\", filename)\n",
        "#         return df\n"
      ],
      "metadata": {
        "id": "uPeiLMdlINPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stories_df = pd.read_csv(\"./user_stories.csv\")\n",
        "\n",
        "# stories = []\n",
        "# for _, r in stories_df.head(3).iterrows():\n",
        "#     ac_list = [ac.strip() for ac in r[\"acceptance_criteria\"].split(\"|\")]\n",
        "#     stories.append({\n",
        "#         \"title\": r[\"title\"],\n",
        "#         \"description\": r[\"description\"],\n",
        "#         \"acceptance_criteria\": ac_list,\n",
        "#         \"domain\": r.get(\"domain\", \"\")\n",
        "#     })\n",
        "\n",
        "# multi_rag = MultiAgentLLM_RAG(\n",
        "#     model=genai,                # your Gemini client\n",
        "#     retrieve_fn=retrieve_policies,\n",
        "#     top_k=3\n",
        "# )\n",
        "\n",
        "# results_rag = multi_rag.process_multiple_stories(stories, delay=3)\n",
        "# df_rag = multi_rag.save_results(results_rag)\n",
        "# import json\n",
        "# print(json.dumps(results_rag, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3NqnMhFIY56",
        "outputId": "1287970a-f8e3-415d-e7fa-079d8bfc12b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saved: multi_agent_rag_results.csv\n",
            "[\n",
            "  {\n",
            "    \"approach\": \"multi_llm_rag\",\n",
            "    \"original_title\": \"Implement GraphQL APIs to enhance performance\",\n",
            "    \"story\": {\n",
            "      \"title\": \"ERROR\",\n",
            "      \"description\": \"\"\n",
            "    },\n",
            "    \"acceptance_criteria\": [],\n",
            "    \"risks\": [],\n",
            "    \"open_questions\": [],\n",
            "    \"qa_notes\": [],\n",
            "    \"processing_time\": 0.6409657001495361,\n",
            "    \"model_used\": \"gemini-2.5-pro\",\n",
            "    \"original_story\": {\n",
            "      \"title\": \"Implement GraphQL APIs to enhance performance\",\n",
            "      \"description\": \"As an AEM headless developer, I want to implement GraphQL APIs to enhance performance, so that the solution aligns with AEM Cloud Service best practices.\",\n",
            "      \"acceptance_criteria\": [\n",
            "        \"GraphQL schema changes must be versioned and documented.\",\n",
            "        \"APIs must support localized content variants.\",\n",
            "        \"Content Fragment Models must define explicit data types for all fields.\"\n",
            "      ],\n",
            "      \"domain\": \"headless\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"approach\": \"multi_llm_rag\",\n",
            "    \"original_title\": \"Configure Core Components to enable headless publishing\",\n",
            "    \"story\": {\n",
            "      \"title\": \"ERROR\",\n",
            "      \"description\": \"\"\n",
            "    },\n",
            "    \"acceptance_criteria\": [],\n",
            "    \"risks\": [],\n",
            "    \"open_questions\": [],\n",
            "    \"qa_notes\": [],\n",
            "    \"processing_time\": 0.5054349899291992,\n",
            "    \"model_used\": \"gemini-2.5-pro\",\n",
            "    \"original_story\": {\n",
            "      \"title\": \"Configure Core Components to enable headless publishing\",\n",
            "      \"description\": \"As an AEM websites developer, I want to configure Core Components to enable headless publishing, so that the solution aligns with AEM Cloud Service best practices.\",\n",
            "      \"acceptance_criteria\": [\n",
            "        \"No JSP scripts or direct /apps modifications are allowed.\",\n",
            "        \"Dispatcher must cache all public content pages for anonymous users.\",\n",
            "        \"All rendered HTML must use HTL context-aware escaping to prevent XSS.\"\n",
            "      ],\n",
            "      \"domain\": \"websites\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"approach\": \"multi_llm_rag\",\n",
            "    \"original_title\": \"Configure JSON Exporter to improve author efficiency\",\n",
            "    \"story\": {\n",
            "      \"title\": \"ERROR\",\n",
            "      \"description\": \"\"\n",
            "    },\n",
            "    \"acceptance_criteria\": [],\n",
            "    \"risks\": [],\n",
            "    \"open_questions\": [],\n",
            "    \"qa_notes\": [],\n",
            "    \"processing_time\": 0.47675514221191406,\n",
            "    \"model_used\": \"gemini-2.5-pro\",\n",
            "    \"original_story\": {\n",
            "      \"title\": \"Configure JSON Exporter to improve author efficiency\",\n",
            "      \"description\": \"As an AEM headless developer, I want to configure JSON Exporter to improve author efficiency, so that the solution aligns with AEM Cloud Service best practices.\",\n",
            "      \"acceptance_criteria\": [\n",
            "        \"Content Fragment Models must define explicit data types for all fields.\",\n",
            "        \"APIs must support localized content variants.\",\n",
            "        \"GraphQL schema changes must be versioned and documented.\"\n",
            "      ],\n",
            "      \"domain\": \"headless\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "results_A = baseline.process_multiple_stories(stories_to_process, delay=0)\n",
        "results_B = multi.process_multiple_stories(stories_to_process, delay=0)\n",
        "\n",
        "def avg_invest_score(r):\n",
        "    inv = r.get(\"invest_assessment\")\n",
        "    if isinstance(inv, dict) and len(inv)>0:\n",
        "        vals = [v for v in inv.values() if isinstance(v, (int,float))]\n",
        "        return float(np.mean(vals)) if vals else np.nan\n",
        "    return np.nan\n",
        "\n",
        "def proxy_score_from_fields(r):\n",
        "    ac = r.get(\"acceptance_criteria\") or []\n",
        "    risks = r.get(\"risks\") or []\n",
        "    oq = r.get(\"open_questions\") or []\n",
        "    qa = r.get(\"qa_notes\") or []\n",
        "    scores = {\n",
        "        \"ac_count\": len(ac),\n",
        "        \"risks_count\": len(risks),\n",
        "        \"oq_count\": len(oq),\n",
        "        \"qa_count\": len(qa) if isinstance(qa, list) else (1 if qa else 0)\n",
        "    }\n",
        "    return scores\n",
        "\n",
        "A_scores = []\n",
        "B_scores = []\n",
        "A_ac_counts = []\n",
        "B_ac_counts = []\n",
        "A_risk_counts = []\n",
        "B_risk_counts = []\n",
        "A_oq = []\n",
        "B_oq = []\n",
        "A_qa = []\n",
        "B_qa = []\n",
        "\n",
        "for ra, rb in zip(results_A, results_B):\n",
        "    A_scores.append(avg_invest_score(ra))\n",
        "    B_scores.append(np.nan)  # placeholder\n",
        "    a_fields = proxy_score_from_fields(ra)\n",
        "    b_fields = proxy_score_from_fields(rb)\n",
        "    A_ac_counts.append(a_fields[\"ac_count\"])\n",
        "    B_ac_counts.append(b_fields[\"ac_count\"])\n",
        "    A_risk_counts.append(a_fields[\"risks_count\"])\n",
        "    B_risk_counts.append(b_fields[\"risks_count\"])\n",
        "    A_oq.append(a_fields[\"oq_count\"])\n",
        "    B_oq.append(b_fields[\"oq_count\"])\n",
        "    A_qa.append(a_fields[\"qa_count\"])\n",
        "    B_qa.append(b_fields[\"qa_count\"])\n",
        "\n",
        "all_ac = np.array(A_ac_counts + B_ac_counts, dtype=float)\n",
        "all_risks = np.array(A_risk_counts + B_risk_counts, dtype=float)\n",
        "all_oq = np.array(A_oq + B_oq, dtype=float)\n",
        "all_qa = np.array(A_qa + B_qa, dtype=float)\n",
        "max_ac = all_ac.max() if all_ac.max()>0 else 1.0\n",
        "max_risks = all_risks.max() if all_risks.max()>0 else 1.0\n",
        "max_oq = all_oq.max() if all_oq.max()>0 else 1.0\n",
        "max_qa = all_qa.max() if all_qa.max()>0 else 1.0\n",
        "\n",
        "def compute_proxy_score(ac, risks, oq, qa):\n",
        "    a = (ac / max_ac)\n",
        "    r = (1 - (risks / (max_risks)))  # fewer risks = better\n",
        "    o = (1 - (oq / (max_oq)))        # fewer open questions = better\n",
        "    q = (qa / max_qa)\n",
        "    score = (0.45*a + 0.25*r + 0.15*o + 0.15*q) * 5.0\n",
        "    return float(np.clip(score, 0, 5))\n",
        "\n",
        "for i, rb in enumerate(results_B):\n",
        "    B_scores[i] = compute_proxy_score(B_ac_counts[i], B_risk_counts[i], B_oq[i], B_qa[i])\n",
        "\n",
        "for i, ra in enumerate(results_A):\n",
        "    if np.isnan(A_scores[i]):\n",
        "        A_scores[i] = compute_proxy_score(A_ac_counts[i], A_risk_counts[i], A_oq[i], A_qa[i])\n",
        "\n",
        "A_scores = np.array(A_scores, dtype=float)\n",
        "B_scores = np.array(B_scores, dtype=float)\n",
        "\n",
        "threshold = 3.0\n",
        "A_binary = (A_scores >= threshold).astype(int)\n",
        "B_binary = (B_scores >= threshold).astype(int)\n",
        "gt = np.ones_like(A_binary)\n",
        "\n",
        "def prf(y_true, y_pred):\n",
        "    tp = int(((y_pred==1) & (y_true==1)).sum())\n",
        "    fp = int(((y_pred==1) & (y_true==0)).sum())\n",
        "    fn = int(((y_pred==0) & (y_true==1)).sum())\n",
        "    precision = tp / (tp+fp+1e-10)\n",
        "    recall = tp / (tp+fn+1e-10)\n",
        "    f1 = 2*precision*recall/(precision+recall+1e-10)\n",
        "    acc = ((y_pred==y_true).sum())/len(y_true)\n",
        "    return precision, recall, f1, acc\n",
        "\n",
        "pA, rA, f1A, accA = prf(gt, A_binary)\n",
        "pB, rB, f1B, accB = prf(gt, B_binary)\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    \"ARM A\": [pA, rA, f1A, accA],\n",
        "    \"ARM B\": [pB, rB, f1B, accB]\n",
        "}, index=[\"Precision\",\"Recall\",\"F1\",\"Accuracy\"])\n",
        "\n",
        "print(metrics_df)\n",
        "\n",
        "metrics_df.loc[[\"Recall\",\"F1\"]].T.plot(kind=\"bar\", figsize=(8,5))\n",
        "plt.ylim(0,1)\n",
        "plt.title(\"ARM A vs ARM B: Recall and F1\")\n",
        "plt.ylabel(\"Score (0-1)\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis=\"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "p4WzN81ogjgp",
        "outputId": "8afaaf59-370a-44e3-8ec6-8fd8468fab23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üéØ SINGLE LLM BASELINE - Processing 3 stories\n",
            "======================================================================\n",
            "\n",
            "[1/3] Processing: Implement GraphQL APIs to enhance performance\n",
            "  ‚úì INVEST avg: 4.33/5 | Time: 30.17s\n",
            "  ‚è≥ Waiting 0s for rate limit...\n",
            "\n",
            "[2/3] Processing: Configure Core Components to enable headless publishing\n",
            "  ‚úì INVEST avg: 4.83/5 | Time: 25.98s\n",
            "  ‚è≥ Waiting 0s for rate limit...\n",
            "\n",
            "[3/3] Processing: Configure JSON Exporter to improve author efficiency\n",
            "  ‚úì INVEST avg: 4.17/5 | Time: 27.12s\n",
            "\n",
            "======================================================================\n",
            "‚úÖ COMPLETED - Single LLM Run Finished\n",
            "======================================================================\n",
            "           ARM A     ARM B\n",
            "Precision    1.0  1.000000\n",
            "Recall       1.0  0.333333\n",
            "F1           1.0  0.500000\n",
            "Accuracy     1.0  0.333333\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
